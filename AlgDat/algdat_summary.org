#+TITLE: AlgDat Summary
#+AUTHOR: Olivier Lischer
#+SETUPFILE: ../latex_includes.conf
#+LATEX_CLASS_OPTIONS: [11pt,twoside,twocolumn,landscape]

\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{AlgDat-HS21}
\fancyhead[L]{Exam Summary}
\fancyfoot[CE,CO]{\leftmark}
\fancyfoot[R]{\thepage}
\fancyfoot[L]{Olivier Lischer}

\tableofcontents
\newpage


* Data Structures 
** Binary Search Tree
#+begin_quote
A Binary Search Tree is [[id:40069be1-38b2-4f4e-bba9-294937a53d0f][Binary Tree]] which stores keys or key-value pairs so
that when you travel in-order all keys are sorted ascending.
#+end_quote

** AVLTree
An AVLTree is a special kind of [[id:c400a6a9-aad8-43aa-a6b7-b22196bac945][Binary Search Tree]].
The AVLTree is self balancing and has therefore better running time guaranties than the normal [[id:c400a6a9-aad8-43aa-a6b7-b22196bac945][Binary Search Tree]].
The tree rebalance itself when the $abs(balance factor) > 1$.
The balance factor is calculated with: =BalanceFactor(Node) = Height(Node.LeftSubtree) - Height(Node.RightSubtree)=


For rebalancing exists two methods:
- [[id:8d8b6221-e7f4-4d82-9efc-e2f44f9ced9d][Cut/Link Algorithm]] aka. [[id:8d8b6221-e7f4-4d82-9efc-e2f44f9ced9d][Trinode restructuring]]
- [[id:bd6a61f7-1b31-461c-9860-848ca5550e04][Rotation Balancing]]

/Running time/:
- find: $O(\log (n))$
- insert: $O(\log (n))$
  - at first find, after that restructure $O(1)$
- delete: $O(\log (n))$
  - at first find, after that restructure $O(\log (n))$

** Cut/Link Algorithm
This algorithm is used by some [[id:c400a6a9-aad8-43aa-a6b7-b22196bac945][Binary Search Tree]] for rebalancing. 

- Input :: A position $x$ of a binary search tree $T$ that has both a parent $y$ and a grandparent $z$
- Output :: Tree $t$ after a trinode restructuring.


1. Let $(a, b, c)$ be a left-to-right (inorder) listing of the positions $x$, $y$ and $z$, and let $(T_1, T_2, T_3, T_4)$ be a left-to-right (inorder) listing of the four subtrees of $x$, $y$ and $z$ not rooted at $x$, $y$ and $z$.
2. Replace the subtree rooted at $z$ with a new subtree rooted at $b$
   1. Let $a$ be the left child of $b$ and let $T_1$ and $T_2$ be the left and right subtrees of $a$.
   2. Let $c$ be the right child of $b$ and let $T_3$ and $T_4$ be the left and right subtrees of $c$.




#+CAPTION: Cut/Link Example
#+NAME: fig:cut-link-example
[[file:img/cut_link.drawio.png]]

** Rotation Balancing

This algorithm is used by some [[id:c400a6a9-aad8-43aa-a6b7-b22196bac945][Binary Search Tree]]s to restructure itself.
The problem with this technique is that you have to check what is required, a left rotation or a right rotation.
Some times a double rotation is required. 


- Input :: A position $x$ of a binary search tree $T$ that has both a parent $y$ and a grandparent $z$
- Output :: Tree $t$ after a trinode restructuring.


1. Let $(a, b, c)$ the inorder listing of the positions $x$, $y$, $z$
2. Do the required rotations until $b$ is at the top.


#+begin_src java
  // right rotation
  BinaryNode rotateWithLeftChild(BinaryNode k2) {
      BinaryNode k1 = k2.left;
      k2.left = k1.right;
      k1.right = k2;
      return k1;
  }

  // left rotation
  BinaryNode rotateWithRightChild( BinaryNode k1 ) {
      BinaryNode k2 = k1.right; // Hilfsknoten
      k1.right = k2.left;
      k2.left = k1;
      return k2;
  }
#+end_src



** Splay Tree

A Splay Tree is a [[id:c400a6a9-aad8-43aa-a6b7-b22196bac945][Binary Search Tree]] which moves the accessed note after the operation to the root.
Even after update or search.
Moving the accessd note to the root is achived using rotation.
You rotate until the access element is at the top.
Splay Trees are usefull when you search often for the same thing.

#+CAPTION: Splaying Algorithm
#+NAME: fig:splaying-algorithm
[[file:img/splaying.png]]

** Graph

A graph consist of *Vertices* and *Edges*.
It exists directed and undirected edges / graphs.
A directed edge has one start node and one end node.
An undirected edge has two nodes which are whether start nor end node.
In a directed graph (Digraph) all edges are directed.
In an undirected graph all edges are undirected.


A Graph is called connected when between every pair of vertices a path exists.

** Graph Terminology

The Terminology used when working with graphs ([[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]]).


- Edges are *incident* (finished) on a vertex
  - $a, d, b$ are incident in $V$
- *Adjacent* (neighboring) vertices
  - $U, V$ are adjacent
- *Degree* of a Vertex: The number of incident edges
  - $X$ has degree 5
- *Parallel edges*
  - $h, i$ are parallel
- *Loop*
  - $j$ is a loop
- *Path*
  - Sequence of vertices and edges
  - starts with a vertex and ends with a vertex
- *Simple Path*
  - all vertices and edges are unique
- *Cycle*
  - cyclic sequence of vertices and edges
- *Simple Cycle*
  - all vertices and edges are unique
- *Strong Connectivity*
  - every vertex can reach every other vertex
- *Distance*
  - The distance of a vertex $v$ to a vertex $w$ is the length of the shortest path between $v$ and $w$


#+CAPTION: Graph Example
#+NAME: fig:graph-example
[[file:img/graph_example.png]]

** How to Store a graph

To store a graph you have a few possibilities.
- [[id:c6d77554-80e2-4f01-87ed-22ee8996f661][Edge List Structure]]
- [[id:2cf21bc2-e669-4cd8-a8ba-75a784d8bcb6][Adjacent List Structure]]
- [[id:8ef66e17-4af0-43ef-89b3-d068501478cf][Adjacent Matrix Structure]]


#+CAPTION: Performance Summary for Graph Data Structures
#+NAME: fig:performance-summary-for-graph-data-structures
[[file:img/graph_data_structure_summary_running_time.png]]

** Edge List Structure

To represent a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]] you could use the Edge list Structure.

The Edge List Structure stores the nodes in a list.
The Edge objects are also stored in a list.
Each edge object holds a reference to the start vertex and to the end reference.


#+begin_src plantuml :file img/edge_list_structure.png
@startuml
class Vertex {
  Object value
}


class Edge {
  Vertex start
  Vertex end
}

@enduml
#+end_src

#+CAPTION: Test
#+RESULTS:
[[file:img/edge_list_structure.png]]


** Adjacent list Structure

To represent a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]] you could use the Adjacent list Structure.

The Adjacent List Structure stores the nodes in a list.
The Edge objects are also stored in a list.
Each edge object holds a reference to the start vertex and to the end reference.
The Vertex object holds a list with references to the edge objects.


#+begin_src plantuml :file img/adjacent_list_structure.png
@startuml
class Vertex {
  Object value
  List<Edge> edges
}


class Edge {
  Vertex start
  Vertex end
}
@enduml
#+end_src

** Adjacent Matrix Structure

To represent a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]] you could use the Adjacent Matrix Structure.

The Adjacent Matrix Structure stores the nodes in a list.
The Edge objects are also stored in a list.
Each edge object holds a reference to the start vertex and to the end reference.
Additionally you have a $n \times n$ matrix / array.
The indexes represent vertexies in the vertex list.
If a edge exists between node 0 and node 1 then in $M[0][1]$ a edge object is stored.
If no connection exists the null value is there. 



#+begin_src plantuml :file img/adjacent_matrix_structure.png
@startuml
class Vertex {
  Object value
  List<Edge> edges
}


class Edge {
  Vertex start
  Vertex end
}
@enduml
#+end_src

** Subgraph

A *Subgraph* $S$ of $G$ is [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]] which contains a set subset of vertices and edges of the Graph $G$.
A *Spanning Subtree* $S$ of $G$ is a graph which contains all vertices of the graph $G$

** Special Kind of Graph / Trees

A free tree $T$ is a undirected graph ([[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]]) so that T is conected an has no cycles.
A forest is a graph without cycles
A Spanning Tree of a connected graph is a [[id:130ba931-67ad-42f1-9289-d2e50d0f5422][Subgraph]] which is also tree

** Transitory Clousre

The Transitory closure of a Digraph ([[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]]) $G$ is another Digraph $G*$ which:
- has the same vertices as $G$
- when in $G$ a directed path betwenn $u$ and $v$ exists ($u \ne v$) then has $G*$ a directed edge from $u$ to $v$

To calculate the Transitory Closure the [[id:ea799493-06ba-4f6d-a802-6cf15965d641][The Floyd-Warshall Algorithm]] is used.


#+CAPTION: Transitory Clousre
#+NAME: fig:transitory-closure
[[file:img/transitiver_abschluss.png]]

** DAG

A DAG is directed acyclic graph.
A [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]] without directed cycles.


#+CAPTION: DAG Example
#+NAME: fig:dag-example
[[file:img/dag.png]]

* Algorithms
** Merge Sort

- Running time :: $O(n \log(n))$

Merge Sort uses the Divide-and-Conquer principle.
It divides the list into 2 splits and the each list again into two lists until the list length is 1.
After that the two lists are merged.
The resulting lists are merged again until you have the sorted list.
#+begin_src java
  public static <T extends Comparable<? super T>> T[] mergeSort(T[] s) {  
    int n = s.length;
    if (n > 1) {
      T[] s1 = Arrays.copyOfRange(s, 0, n/2);
      T[] s2 = Arrays.copyOfRange(s, n/2, n);
      s1 = mergeSort(s1);
      s2 = mergeSort(s2);
      s = merge(s1, s2);
    }
    return s;
  }

  static <T extends Comparable<? super T>> T[] merge(T[] a, T[] b) {
    T[] s = newInstance(a, a.length * 2);
    int ai = 0; // First Element in 'Sequence' A
    int bi = 0; // First Element in 'Sequence' B
    int si = 0; // Last Element in 'Sequence' S
    while (!(ai == a.length) && !(bi == b.length)) {
      if (a[ai].compareTo(b[bi]) < 0) {
        s[si++] = a[ai++];
      }
      else {
        s[si++] = b[bi++];
      }
    }
    while (!(ai == a.length)) {
      s[si++] = a[ai++];
    }
    while (!(bi == b.length)) {
      s[si++] = b[bi++];
    }
    return s;
  }
#+end_src

#+CAPTION: Runtime Summary
#+NAME: fig:runtime-summary
[[file:img/sort_algorithm_summary_runtime.png]]

** Quick Sort

- running time :: $O(n \log(n))$ expected
  
Quick Sort uses the Divide-and-Conquer principle.
1. A random element $x$ is choosen (the *pivot*).
2. Divide
   1. All elements smaller than $x$ go to $S$
   2. All elements greater than $x$ go to $G$
   3. All elements equal $x$ go to $E$
3. Repeate 2 for each list until list length 1
4. merge from lower to equal to higher
  

#+CAPTION: Quick Sort Tree
#+NAME: fig:quick-sort-tree
[[file:img/quick_sort_tree.png]]

#+begin_src java
  /*
   ,* @param a
   ,*          The leftbound of the part that shall be sorted.
   ,* @param b
   ,*          The rightbound of the part that shall be sorted.
   ,*/
  public <T> void inPlaceQuickSort(T[] sequence, Comparator<T> comp, int a, int b) {
      T temp;
      if (a >= b)
	  return;
      T pivot = sequence[b];
      int l = a;
      int r = b - 1;
      while (l <= r) {
	  while (l <= r && comp.compare(sequence[l], pivot) <= 0) {
	      l++;
	  }
	  while (r >= l && comp.compare(sequence[r], pivot) >= 0) {
	      r--;
	  }
	  if (l < r) {
	      temp = sequence[l];
	      sequence[l] = sequence[r];
	      sequence[r] = temp;
	  }
      }
      temp = sequence[l];
      sequence[l] = sequence[b];
      sequence[b] = temp;
      /*  Move index if sequence of equal elements. E.g.:
       ,*  |---+---+---+---+---+---+---+---+---+---+---+---+---|
       ,*  |   |   | 5 | 5 | 2 | 8 | 8 | 8 | 8 |   |   |   |   |
       ,*  |---+---+---+---+---+---+---+---+---+---+---+---+---|
       ,*    a                   l <-------- l               b
       ,*/
      while ((l > a) && (comp.compare(sequence[l], sequence[l-1]) == 0)) { 
	  l--;
      }
      while ((r < b) && (r > a) && (comp.compare(sequence[r], sequence[r+1]) == 0)) {
	  r++;
      }
      inPlaceQuickSort(sequence, comp, a, l - 1);
      inPlaceQuickSort(sequence, comp, r + 1, b);
  }
#+end_src

** Lower Bound Search Algorithm

Every sorting algorithm which uses comparing has a minimal running time of $\log(n!)$.
In O notation this is $O(n \log(n))$.

\begin{align}
\log(n!) &\geq \log{(\frac{n}{2})^{\frac{n}{2}}} = \frac{n}{2}\log(\frac{n}{2}) \\
n! &\geq \sqrt{2\pi \cdot n}(\frac{n}{2})^2 \rightarrow O(n \log n)
\end{align}

** Bucket Sort

- running time :: $O(n + N)$

Bucket Sort is Sorting algorithm which does not use any compares to achieve the sorting.

To sort something with bucket sort you need a key.
This key must have a specific range $[0, N-1]$.
Then you create an array of $N$ empty lists.
Then you move the value from initial unsorted list into the array.
The key of the element specifies the location in the array.
After the initial list is cleared you filled again by iterating over the array.

#+begin_src java
  public List<T> bucketSort(List<T> S, int N) {
      List<T>[] buckets = new ArrayList[N];

      while (!S.isEmpty()) {
	  T f = S.first();
	  (k,o) = S.remove(f);
	  buckets[k].insertLast((k,o));
      }

      for (int i = 0; i < N; i++) {
	  while (!buckets[i].isEmpty()) {
	      T f = buckets[i].first();
	      (k,o) = B[i].remove(f);
	      S.insertLast((k,o));
	  }
      }
  }

#+end_src

** Radix Sort

Radix Sort is a sorting algorithm for lexicographical sorting based on [[id:ca0db7ac-fbf2-4f5f-9a71-aa16d808639d][Bucket Sort]].

#+CAPTION: Radix Sort of a 4-Bit Integer
#+NAME: fig:radix-sort-of-a-4-bit-integer
[[file:img/radix_sort.png]]

#+begin_src java
  public void radixSort(String[] data) {
    // find max string-length
    int maxLength = -1;
    OptionalInt max = Arrays.stream(data).mapToInt(str -> str.length()).max();
    if (max.isPresent()) {
      maxLength = max.getAsInt();
    } else {
      return;
    }

    // bucketsort from max index to first index
    for (int i = maxLength - 1; i >= 0; i--) {
      bucketSort(data, i);
    }

  }

  protected void bucketSort(String[] data, int index) {
    Arrays.stream(data).forEachOrdered(str -> {
      if (str.length() <= index) {
        buckets[0].addLast(str);
      } else {
        buckets[str.charAt(index) - 'a' + 1].addLast(str);
      }
    });

    String[] phase2Array = Arrays.asList(buckets).stream().flatMap(List::stream)
        .toArray(String[]::new);
    System.arraycopy(phase2Array, 0, data, 0, phase2Array.length);
    Arrays.stream(buckets).parallel().forEach(list -> list.clear());
  }
#+end_src

** Boyere-Moore

- running time :: $O(n\cdot m + s)$

The Boyere-Moore Algorithm is used for [[id:b2e6fef1-7dda-495a-8f4d-2adbf4e529a2][Pattern Matching]].
Instead to compare the pattern from the beginning it starts at the end.

1. align start character of search string with pattern
2. compare the n-th character of pattern with search string
3. chars equal: $n = n-1$ and go to 2.
4. not equal: move pattern forward
   1. mismatched character occurs: move pattern forward to mismatched (last occurence function)
   2. else: move whole pattern after the mismatched position


The last occurence funciton returns the index of the where the charachter $x$ occurs last in the pattern ([[fig:lastOccurence]]).

#+LABEL: fig:lastOccurence
#+CAPTION: Last Occurrence Function
[[file:img/lastOccurrence.png]]

#+CAPTION: Boyere-Moore Algorithm
[[file:img/boyere_moore.png]]


\begin{algorithm}
  \caption{Boyer-Moore Algorithm}
  \begin{algorithmic}[1]
    \Procedure{BoyerMooreMatch}{$T, P, \Sigma$}
    \State $L \leftarrow lastOccurenceFunction(P, \Sigma)$
    \State $i \leftarrow m - 1$
    \State $j \leftarrow m - 1$
    \Repeat
    \If{$T[i] = P[j]$}
    \If{$j = 0$}
    \State \textbf{return $i$} \{ match at i \}
    \Else
    \State $i \leftarrow i - 1$
    \State $j \leftarrow j - 1$
    \EndIf
    \State \{ charchter-jump \}
    \State $l \leftarrow L[T[i]]$
    \State $i \leftarrow i + m - min(j, 1 + l)$
    \State $j \leftarrow m - 1$
    \EndIf
    \Until{$i > n - 1$}
    \State \textbf{return} $b$ \{ The gcd is b \}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** KMP

- running time :: O(m + n)


The KMP Algorithm is a [[id:b2e6fef1-7dda-495a-8f4d-2adbf4e529a2][Pattern Matching]] Algorithm.
KMP compares the pattern with text from left to right.
But it moves the pattern smarter than Brute-Force.

The Algorithm has two phases:
1. calculating the *failure function*
   - [[id:f05c4d8e-be88-4bb4-b32b-ee7dbbe38e8f][Calculating the Failure Function for KMP]]
2. the actual pattern matching


1. If $T[i] = P[i]$
   1. is pattern found, then return start position
   2. otherwise increment $i$ and $j$
2. otherwise if $j > 0$ 
   1. then $j$ will become the value from the $failureFunction(j)$
   2. else $i = i + $


*Example:*

KMP according to figure [[fig:kmp]]:
1. the first 5 comparisons are matching
2. 6 does not match
   1. check if 5 could be an prefix (failure function)
   2. yes, the first character of the pattern must not be compared
3. 7 does not match
   1. check error function
   2. 0 \rightarrow align pattern to current position
4. and so on

#+LABEL: fig:kmp
#+CAPTION: KMP Example
[[file:img/kmp_example.png]]


\begin{algorithm}
  \caption{KMP Algorithm}
  \begin{algorithmic}[1]
    \Procedure{KMPMatch}{$T, P$}
    \State $F \leftarrow failureFunction(P)$
    \State $i \leftarrow 0$ \{ Location in search string \}
    \State $j \leftarrow 0$ \{ Location in pattern \}
    \While{$i < m-1$}
    \If{$T[i] = P[i]$}
    \If{$j = m - 1$} \{ m length of pattern \}
    \State \textbf{return} $i - m + 1$ \{ match \}
    \Else
    \State $i \leftarrow i + 1$
    \State $j \leftarrow j + 1$
    \EndIf
    \Else
    \If{$j > 0$}
    \State $j \leftarrow F[j-1]$
    \Else
    \State $i \leftarrow i + 1$
    \EndIf
    \EndIf
    \EndWhile
    \textbf{return} -1 \{ no match \}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** Failure Function KMP

- running time :: O(m)


The Failure Function for KMP ([[id:a00f330a-ad9e-4e67-9157-db6382cffe64][KMP Algorithm]]) is defined as follows:
#+begin_quote
$F(j)$ is defined as the longest prefix from P[0..j] so that this also is the suffix from P[1..j].
#+end_quote

Example according to figure [[fig:kmpFailure]]:
- j = 0 :: a is only prefix, but not suffix
- j = 1 :: b is only a suffix
- j = 2,3 :: a is suffix (0) and a prefix
- j = 4 :: Now the suffix is *ab*, but this could be also the prefix
- j = 5 :: Now the suffix is *aba*, but this could be also the prefix

#+LABEL: fig:kmpFailure
#+CAPTION: Failure Function for KMP
[[file:img/kmp_failure_function.png]]


\begin{algorithm}
  \caption{KMP Failure Function}
  \begin{algorithmic}[1]
    \Procedure{failureFunction}{$P$}
    \State $F[0] \leftarrow 0$
    \State $i \leftarrow 1$ \{ Location in pattern \}
    \State $j \leftarrow 0$ 
    \While{$i < m$}
    \If{$P[i] = P[j]$}
    \State $F[i] \leftarrow  j + 1$
    \State $i \leftarrow i + 1$
    \State $j \leftarrow j + 1$
    \ElsIf{$j > 0$}
    \State $j \leftarrow F[j-1]$
    \Else
    \State $F[i] \leftarrow 0$
    \State $i \leftarrow i + 1$
    \EndIf
    \EndWhile
    \textbf{return} -1 \{ no match \}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** Tries

A *Trie* is a data structure (a tree [[id:8fa89c50-bb97-4210-b53f-02035a1adfa1][Tree]]) to represent a set of strings.
Tries are used to perform fast pattern matching.


The Default-Trie / Standard-Trie has:
- each node except the root node has exactly one symbol
- Every path from the root to a leaf is a word in the set


The Default-Trie stores every symbol in a node.
But sometimes a node has only one next node.
This symbol and the next node can be merged together in one node.


#+CAPTION: Example of Tries
#+NAME: fig:example-of-tries
[[file:img/tries.png]]


The Suffix-Trie for a string is a compress trie ([[id:d0754cbc-960f-425d-83e4-396938cbb473][Tries]]) which stores all suffixes.

#+CAPTION: Suffix Trie
#+NAME: fig:suffix-trie
[[file:img/suffix_trie.png]]

** DFS

Depth-First search is a technique to traverse a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]].
As the name says you go deep and then wide (see [[fig:dfs-example]]).


#+CAPTION: DFS Example
#+NAME: fig:dfs-example
[[file:img/dfs.png]]



\begin{algorithm}
  \caption{DFS Algorithm}
  \begin{algorithmic}[1]
    \Procedure{DFS}{$G$}
    \ForAll{$u \in G.vertices()$}
    \State $setLabel(u, UNEXPLORED)$
    \EndFor

    \ForAll{$e \in G.edges()$}
    \State $setLabel(e, UNEXPLORED)$
    \EndFor

    \ForAll{$v \in G.vertices()$}
    \If{$getLabel(v) = UNEXPLORED$}
    \State $DFS(G, v)$
    \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
  \begin{algorithmic}[1]
    \Procedure{DFS}{$G, v$}
    \State $setLabel(v, VISITED);$
    \ForAll{$e \in G.incidentEdges(v)$}
    \If{$getLabel(e) = UNEXPLORED$}
    \State $w \leftarrow opposite(v,e)$
    \If{$getLabel(w) = UNEXPLORED$}
    \State $setLabel(e, DISCOVERED)$
    \State $DFS(G, w)$
    \Else
    \State $setLabel(e, BACK)$
    \EndIf
    \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** DFS for finding path

[[id:c6045230-1e93-4222-9f2d-d5e2946eab25][DFS]] can be used to find a path between two vertices in a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]].
Every time you discovered a new edge, the edge is added to a stack.
If you come back from this edge (return from the recursion) you remove it from the stack.
If you finally found the searched vertex the path to this is stored in the stack.




\begin{algorithm}
  \caption{Find path with DFS}
  \begin{algorithmic}[1]
    \Procedure{pathDFS}{$G, v, z$}
    \State $setLabel(v, VISITED)$
    \State $S.push(v)$ \{ Stores the path \}
    \If{$v = z$}
    \State \textbf{finish: result is} $S.elements()$
    \EndIf
    \ForAll{$e \in G.incidentEdges(v)$}
    \If{$getLabel(e) = UNEXPLORED$}
    \State $w \leftarrow opposite(v, e)$
    \If{$getLabel(w) = UNEXPLORED$}
    \State $setLabel(e, DISCOVERY)$
    \State $S.push(e)$
    \State $pathDFS(G, w, z)$
    \State $S.pop()$
    \Else
    \State $setLabel(e, BACK$
    \EndIf
    \EndIf
    \EndFor
    \State $S.pop()$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** DFS For finding cycleso

[[id:c6045230-1e93-4222-9f2d-d5e2946eab25][DFS]] can be used to find cycles in a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]].
Using a stack you store the path from the start to the end vertex.
DFS has found a cycle as soon as you would mark a edge with *BACK*.


\begin{algorithm}
  \caption{Find Cycles with DFS}
  \begin{algorithmic}
    \Procedure{$cyclesDFS$}{$G, v$}
    \State $setLabel(v, VISITED)$
    \State $S.push(v)$
    \ForAll{$e \in G.incidentEdges(v)$}
    \If{$getLabel(e) = UNEXPLORED$}
    \State $w \leftarrow opposite(v, e)$
    \State $S.push(e)$
    \If{$getLabel(w) = UNEXPLORED$}
    \State $setLabel(e, DISCOVERY)$
    \State $cycleDFS(G, w)$
    \State $S.pop()$
    \Else
    \State $T \leftarrow new empty stack$
    \Repeat
    \State $o \leftarrow S.pop()$
    \State $T.push(0)$
    \Until{$o = w$}
    \State \textbf{finish: result in} $T.elements()$
    \EndIf
    \EndIf
    \EndFor
    \State $S.pop()$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** BFS

Breath-First Search is a technique to traverse a graph.
BFS visits one level after another.
The start vertex is marked as visited.
Then all adjacent vertexes are visited.
BFS uses a [[id:6607dc69-210b-4ac7-b020-f2b734f160e4][Queue]] to store which vertex should be visited next.


#+CAPTION: BFS Example
#+NAME: fig:bfs-example
[[file:img/bfs_example.png]]


\begin{algorithm}
  \caption{BFS Algorithm}
  \begin{algorithmic}
    \Procedure{$BFS$}{$G$}
    \ForAll{$u \in G.vertices()$}
    \State $setLabel(u, UNEXPLORED)$
    \EndFor

    \ForAll{$e \in G.edges()$}
    \State $setLabel(e, UNEXPLORED)$
    \EndFor

    \ForAll{$v \in G.evertices()$}
    \If{$getLabel(v) = UNEXPLORED$}
    \State $DFS(G, v)$
    \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
  \begin{algorithmic}
    \Procedure{$BFS$}{$G, s$}
    \State $L_0 \leftarrow new empty sequence$
    \State $L_0.insertLast(s)$
    \State $setLabel(s, VISITED)$
    \State $i \leftarrow 0$
    \While{$\neg L_i.isEmpty()$}
    \State $L_{i+1} \letarrow new empty sequence$
    \ForAll{$v \in L_i.elements()$}
    \ForAll{$e \in G.incidentEdges(v)$}
    \If{$getLabel(e) = UNEXPLORED$}
    \State $w \leftarrow opposite(v,e)$
    \If{$getLabel(w) = UNEXPLORED$}
    \State $setLabel(e, DISCOVERY)$
    \State $setLabel(w, VISITED)$
    \State $L_{i+1}.insertLast(w)$
    \Else
    \State $setLabel(e, CROSS)$
    \EndIf
    \EndIf
    \EndFor
    \EndFor
    \EndWhile
    \State $i \leftarrow i + 1$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** DFS vs. BFS

A comparision of [[id:c6045230-1e93-4222-9f2d-d5e2946eab25][DFS]] and [[id:4e3b8a77-ac48-4f1d-a8a8-dbe48eaf187c][BFS]].


#+CAPTION: DFS vs. BFS
#+NAME: fig:dfs-vs-bfs
[[file:img/dfs_vs_bfs.png]]

** Floyd-Warshall

The Floyd-Warshall algorithm is used to calculate the Transitory closure of a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]] $G$.


\begin{algorithm}
  \caption{Floyd-Warshall's Algorithm}
  \begin{algorithmic}
    \Procedure{$FloydWarshall$}{$G$}
    \State $i \gets 1$
    \ForAll{$v \in G.vertices()$}
    \State $denote v as v_i$
    \State $i \gets i + 1$
    \EndFor
    \State $G_0 \gets G$
    \For{$k \gets 1$ \textbf{to} $n$}
    \State $G_k \gets G_{k-1}$
    \For{$i \gets 1 \textbf{to} n (i \ne k)$}
    \For{$j \gets 1 \textbf{to} n (j \ne i,k)$}
    \If{$G_{k-1}.areAdjacent(v_i,v_k) \land G_{k-1}.areAdjacent(v_i, v_j)$}
    \If{$\neg G_k.areAdjacent(v_i, v_j)$}
    \State $G_k.insertDirectedEdge(v_i, v_j, k)$
    \EndIf
    \EndIf
    \EndFor
    \EndFor
    \EndFor
    \State \textbf{return} G_n
    \EndProcedure
  \end{algorithmic}
\end{algorithm}



From $v_5$ to $v_4$ exists a directed path over $v_1$.
There for are $j = 4, i = 5, k = 1$.


#+CAPTION: Floyd-Warshall Example
#+NAME: fig:floyd-warshall-example
[[file:img/floyd_warshall.png]]

** Topological Sorto

Topological Sort is used to sort / enumerate vertices so that for an edge ($u$, $v$) $u < v$ true is.


#+CAPTION: Topological Sort Example
#+NAME: fig:topological-sort-example
[[file:img/topological_sort_example.png]]


Topological Sort is just a [[id:c6045230-1e93-4222-9f2d-d5e2946eab25][DFS]] where you label the vertices.


\begin{algorithm}
  \caption{Topological Sort using DFS}
  \begin{algorithmic}[1]
    \Procedure{topologicalDFS}{$G$}
    \ForAll{$u \in G.vertices()$}
    \State $setLabel(u, UNEXPLORED)$
    \EndFor

    \ForAll{$e \in G.edges()$}
    \State $setLabel(e, UNEXPLORED)$
    \EndFor

    \ForAll{$v \in G.vertices()$}
    \If{$getLabel(v) = UNEXPLORED$}
    \State $topologicalDFS(G, v)$
    \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
  \begin{algorithmic}[1]
    \Procedure{topologicalDFS}{$G, v$}
    \State $setLabel(v, VISITED);$
    \ForAll{$e \in G.incidentEdges(v)$}
    \If{$getLabel(e) = UNEXPLORED$}
    \State $w \gets opposite(v,e)$
    \If{$getLabel(w) = UNEXPLORED$}
    \State $setLabel(e, DISCOVERED)$
    \State $topologicalDFS(G, w)$
    \Else
    \State $setLabel(e, n)$
    \EndIf
    \EndIf
    \EndFor
    \State $n \gets n - 1$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** Dijkstra

The Dijkstra Algorithm is used to calculate the distance to all vertices from a start vertex $s$ in a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]].
Dijkstra has a few requirements:
- The graph is connected
- the edges are undirected
- the edge weight is not negative


You build a cloud of vertices.
Beginning with the start vertex $s$ you add one vertex after one to the cloud.
With each vertex $v$ we store a property which holds the distance from $s$ to $v$.
After each iteration we add the vertex with the lowest distance and update the distance of all adjacent vectors.


#+CAPTION: Dijkstra Algorithm Example
#+NAME: fig:dijkstra-algorithm-example
[[file:img/dijkstra_algorithm_example.png]]


\begin{algorithm}
  \caption{Dijkstra Algorithm}
  \begin{algorithmic}
    \Procedure{$DikstraDistance$}{$G, s$}
    \State $Q \gets$ new heap-based adaptable PQ
    \State \{ Initialization \}
    \ForAll{$v \in G.vertices()$}
    \If{$v = s$}
    \State $setDistance(v, 0)$
    \Else
    \State $setDistance(v, \infty)$
    \EndIf
    \EndFor

    \While{$\neg Q.isEmpty()$}
    \State $u \gets Q.removeMin().getValue()$
    \ForAll{$e \in G.incidentEdges(u)$}
    \State \{ relax edge e\}
    \State $z \gets G.opposite(u, e)$
    \State $r \gets getDistance(u) + weight(e)$
    \If{$r < getDistance(z)$}
    \State $setDistance(z,r)$
    \State $Q.replaceKey(getLocator(z), r)$
    \EndIf
    \EndFor
    \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

** Bellman-Ford

The Bellman-Ford algorithm is use to caculate the distance from a vertex to every other vertex in a [[id:e2f5e1e5-3ea9-477e-96cd-c579d79d2f98][Graph]].
But other then the [[id:693cdd8b-8121-4801-a06a-8e9cc742ad9d][Dijkstra Algorithm]] the Bellman-Ford algorithm can also work with negative edge weights.
Requirements:
- directed edges
- no negative weighted cycles


\begin{algorithm}
  \caption{Bellman-Ford Algorithm}
  \begin{algorithmic}
    \Procedure{$BellmanFord$}{$G,s$}
    \ForAll{$v \in G.vertices()$}
    \If{$v = s$}
    \State $setDistance(v, 0)$
    \Else
    \State $setDistance(v, \infty)$
    \EndIf
    \EndFor

    \State $n \gets G.numVertices()$

    \For{$i \gets 1$ \textbf{to} $n-1$}
    \ForAll{$e \in G.edges()$}
    \State $u \gets G.origin(e)$
    \State $z \gets G.opposite(u,e)$
    \State $r \gets getDistance(u) + weight(e)$
    \If{$r < getDistance(z)$}
    \State $setDistance(z,r)$
    \EndIf
    \EndFor
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


#+CAPTION: Bellman-Ford Example
#+NAME: fig:bellman-ford-example
[[file:img/bellman_ford_example.png]]

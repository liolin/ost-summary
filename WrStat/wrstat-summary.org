#+TITLE: WrStat
#+AUTHOR: Olivier Lischer
#+SETUPFILE: ../latex_includes.conf
#+LATEX_CLASS_OPTIONS: [10pt,twoside,landscape]
#+LATEX_HEADER: \usepackage{caption}


\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{WrStat-HS23}
\fancyhead[L]{Exam Summary}
\fancyfoot[CE,CO]{\leftmark}
\fancyfoot[R]{\thepage}
\fancyfoot[L]{Olivier Lischer}

#+LATEX: \begin{multicols}{2}
* Kombinatorik
** Zählregel
- Disjunkte Vereinigung: \(|A \cup B| = |A| + |B|\)
- Vereinigung: \(|A \cup B| = |A| + |B| - |A \cap B|\)
- Paare = Produkt: \(|A \times B| = |A| \cdot |B|\)
  
** Reihenfolge / Permutation
Jeder Platz im Hörsaal wird belegt:
\begin{align*}
  P_n &= \underbrace{\#\text{\{Plätze für 1. Objekt\}}}_{n} \cdot \underbrace{\#\text{\{Plätze für 2. Objekte\}}}_{n-1} \cdot \ldots \cdot \underbrace{\#\{\text{Plätze für n. Objekte\}}}_{1} \\
  &= n \cdot (n-1) \cdot \ldots \cdot 1 = n!  \\
  &= \underbrace{\#\text{Plätze für 1. Objekt}}_{n} \cdot \underbrace{\#\text{Anordnung von n-1 Objekten}}_{P_{n-1}} \\
  &= n \cdot P_{n-1} = n \cdot (n - 1)! = n!
\end{align*}

** Anzahl / Auswahl Problem
Auf wie viele Arten kann man \(k\) Plätze aus \(n\) Plätzen auswählen?
16 Studenten (\(k\)) platzieren sich auf 32 Plätzen (\(n\)).

\begin{align*}
\text{\#Auswahlprozesse} &= n \cdot (n - 1) \cdot \ldots \cdot (n - k + 1) \\
&= \frac{n!}{(n-k)!} \\
&= \binom{n}{k}
\end{align*}

Binominal Koeffizient (funktioniert meist nicht gut, Taschenrechner können grosse \(n!\) nicht rechnen)
Besser so:
\[
\frac{n \cdot (n - 1) \cdot (n - 2) \cdot \ldots \cdot (n-k + 1)}{1 \cdot 2 \cdot 3 \cdot \ldots \cdot k}
\]

** Variation
Auch als Perlenkette bekannt
\[
\text{\#Möglichkeiten} = k[\text{Farben}]^{n[\text{Längen}]}
\]

* Ereignisse und Wahrscheinlichkeit
** Begriffe
| Begriff                                               | Model                         |
|-------------------------------------------------------+-------------------------------|
| Versuchausgang, Elementarereignis                     | \(\omega\)                    |
| alle Versuchsausgänge                                 | \(\Omega\)                    |
| Ereignis                                              | \(A \subset \Omega\)          |
| Ereignis ist eingetreten                              | \(\omega \in A\)              |
| sicheres Ereignis, tritt immer ein                    | \(\Omega\)                    |
| unmögliches Ereignis, kann nicht eintreten            | \(\emptyset\)                 |
| \(A\) und \(B\) tretten ein                           | \(A \cap B\)                  |
| \(A\) oder \(B\) tretten ein                          | \(A \cup B\)                  |
| \(A\) hat \(B\) zur Folge, wenn \(A\) dann auch \(B\) | \(A \subset B\)               |
| nicht A                                               | \(\overline{A} = \Omega \setminus A\) |

** Bedingte Wahrscheinlichkeit
Wahrscheinlichkeit, dass ein Toter ein rotes Shirt trägt (Wir untersuchen nur die Toten und schauen ob er ein Rotes Shirt trägt)
\[
P(R|T) = \frac{P(R \cap T)}{P(T)}
\]

*Satz von Bayes*:
\[
P(R|T) \cdot P(T) = P(R \cap T) = P(T|R) \cdot P(R)
\]

*Satz der totalen Wahrscheinlichkeit*
\begin{align*}
&P(T \cap G) &= P(T|G) \cdot P(G) \\
+&P(T \cap B) &= P(T|B) \cdot P(B) \\
+&P(T \cap R) &= P(T|R) \cdot P(R) \\
=&P(T)
\end{align*}
* Zufallsvariabeln
** Erwartungswert

\begin{equation}
\begin{split} \label{eqn:erwartungs-wert}
E(X) = \sum_{i=1}^{n}g_iP(A_i) \\
\end{split} 
\end{equation}
** Varianz
\[
var(X) = E(X^2) - E(X)^2
\]
* Verteilungsfunktion und Wahrscheinlichkeitsdichte
Die Verteilungsfunktion beschreibt die Wahrscheinlichkeiten der Werte einer Zufallsvariable:
\[
F(X) = P(X \le x)
\]

$\phi(x)$ ist die Ableitung von $F(x)$ und entspricht der Verteilungsdichte Funktion.
\[
\phi(x) = \frac{d}{dx}F(x) = F'(x)
\]

- Wahrscheinlichkeit: $P(X = x) \rightarrow \phi(x) dx$
- Summe: $\sum_x \rightarrow \int_\infty^\infty$
- $E(X) = \sum_x x \cdot P(X = x) \rightarrow E(X) = \int_\infty^\infty x \cdot \phi(x) dx$
Wichtig: Erkennen, was ist der Wert, was ist der Erwartungswert

* Exponential- / Erlang- / Poisson-Verteilung
** Exponentialverteilung
- Dichtefunktion :: $ae^{-ax}, a > 0$
- Verteilungsfunktion :: $1 - e^{-ax}$
- Erwartungswert :: $\frac{1}{a}$
- Varianz :: $\frac{1}{a^2}$
- Median :: $\frac{1}{a}\log{2}$

** Possonverteilung
- Wahrscheinlichkeit :: $P_\lambda(k) = \frac{\lambda^k}{k!}e^{-\lambda}$
- Erwartungswert :: $\lambda$
- Varianz :: $\lambda$
* Normalverteilung
** Normalverteilung
- Dichtefunktion :: $\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
- Verteilungsfunktion :: keine elementare Funktion (Tabelle nutzen)
- Erwartungswert :: $\mu$
- Varianz :: $\sigma$
- Median :: $\mu$
* Binominalverteilung
** Binominalverteilung
- Wahrscheinlichkeit :: $P(k) = \binom{n}{k}p^k(1-p)^{n-k}$
- Verteilungsfunktion :: $F(k) = \sum_{i=0}^{k}\binom{n}{i}p^i(1-p)^{n-i}$
- Erwartungswert :: $np$
- Varianz :: $np(1-p)$
* Schätzen
** Schätzen
Mittelwert ist häufig ein guter Schätzer
** t-Verteilung
t-Verteilung sollte dann verwendet werden, wenn man wenig Daten hat, aber es normall Verteilt ist (kleine $n$).

* Hypothesentest
** Vorgehen Hypothesentest
1. Nullhypothese $H_0$ und Alternativhypothese $H_1$
2. Testgrösse und Verteilung unter der Annahme der Nullhypothese
3. Wahl des Signifikanzniveaus $\alpha$
4. Kritischer Wert für Testgrösse, die nur mit Wahrscheinlichkeit $\alpha$ erreicht wird
5. Kritischer Wert erreicht $\Rightarrow$ Nullhypothese $H_0$ verwerfen

** t-Test
Ist der neue Dünger besser?
Die Stichproben $X_1, \ldots, X_n$ und $Y_1, \ldots, Y_m$ mit gleicher Varianz haben den gleichen Erwartungswert.

\[
\overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]

\[
S_X^2 = \frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2
\]

\[
t = \frac{\overline{X} - \overline{Y}}{\sqrt{(n-1)S_X^2 + (m-1)S_Y^2}}\sqrt{\frac{nm(n+m-2)}{n+m}}
\]

$t_{krit}$ kann aus der t-Verteilung abgelesen werden.
$k$ erhält man durch $n+m-2$.
Wenn $t_{krit}$ überschritten wird, muss $H_0$ verworfen werden.
* Test einer Verteilung
** \Chi^2-Test

\[
D = \sum_{i=1}^d\frac{(n_i-np_i)^2}{np_i}
\]

D > D_+ \Rightarrow Daten passen nicht (H_0 verwerfen)

D < D_− \Rightarrow Daten passen zu gut, ist ein Hinweis auf Betrug
** Kolmogorov-Smirnov-Test

#+LATEX: \end{multicols}

